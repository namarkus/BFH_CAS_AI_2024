{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namarkus/BFH_CAS_AI_2024/blob/main/Day17/torchrl_getting_started_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxi5RrXCItIV"
      },
      "source": [
        "\n",
        "# Get started with Environments, TED and transforms\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install gymnasium==0.29.1 torch torchrl tensordict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAxkRiQvRZvz",
        "outputId": "8ee22b91-62e4-428a-8068-18ae01b708f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Collecting tensordict\n",
            "  Downloading tensordict-0.7.1-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.7.1-cp311-cp311-manylinux1_x86_64.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, tensordict, torchrl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0\n",
            "    Uninstalling gymnasium-1.0.0:\n",
            "      Successfully uninstalled gymnasium-1.0.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 tensordict-0.7.1 torch-2.6.0 torchrl-0.7.1 triton-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1qLSuQCItIZ"
      },
      "source": [
        "Welcome to the getting started tutorials!\n",
        "\n",
        "Below is the list of the topics we will be covering.\n",
        "\n",
        "- `Environments, TED and transforms <gs_env_ted>`;\n",
        "- `TorchRL's modules <gs_modules>`;\n",
        "- `Losses and optimization <gs_optim>`;\n",
        "- `Data collection and storage <gs_storage>`;\n",
        "- `TorchRL's logging API <gs_logging>`.\n",
        "\n",
        "If you are in a hurry, you can jump straight away to the last tutorial,\n",
        "`Your own first training loop <gs_first_training>`, from where you can\n",
        "backtrack every other \"Getting Started\" tutorial if things are not clear or\n",
        "if you want to learn more about a specific topic!\n",
        "\n",
        "## Environments in RL\n",
        "\n",
        "The standard RL (Reinforcement Learning) training loop involves a model,\n",
        "also known as a policy, which is trained to accomplish a task within a\n",
        "specific environment. Often, this environment is a simulator that accepts\n",
        "actions as input and produces an observation along with some metadata as\n",
        "output.\n",
        "\n",
        "In this document, we will explore the environment API of TorchRL: we will\n",
        "learn how to create an environment, interact with it, and understand the\n",
        "data format it uses.\n",
        "\n",
        "## Creating an environment\n",
        "\n",
        "In essence, TorchRL does not directly provide environments, but instead\n",
        "offers wrappers for other libraries that encapsulate the simulators. The\n",
        ":mod:`~torchrl.envs` module can be viewed as a provider for a generic\n",
        "environment API, as well as a central hub for simulation backends like\n",
        "[gym](https://arxiv.org/abs/1606.01540) (:class:`~torchrl.envs.GymEnv`),\n",
        "[Brax](https://arxiv.org/abs/2106.13281) (:class:`~torchrl.envs.BraxEnv`)\n",
        "or [DeepMind Control Suite](https://arxiv.org/abs/1801.00690)\n",
        "(:class:`~torchrl.envs.DMControlEnv`).\n",
        "\n",
        "Creating your environment is typically as straightforward as the underlying\n",
        "backend API allows. Here's an example using gym:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ASuLFHfItIb"
      },
      "outputs": [],
      "source": [
        "from torchrl.envs import GymEnv\n",
        "\n",
        "env = GymEnv(\"Pendulum-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmTFGcMUItIc"
      },
      "source": [
        "## Running an environment\n",
        "\n",
        "Environments in TorchRL have two crucial methods:\n",
        ":meth:`~torchrl.envs.EnvBase.reset`, which initiates\n",
        "an episode, and :meth:`~torchrl.envs.EnvBase.step`, which executes an\n",
        "action selected by the actor.\n",
        "In TorchRL, environment methods read and write\n",
        ":class:`~tensordict.TensorDict` instances.\n",
        "Essentially, :class:`~tensordict.TensorDict` is a generic key-based data\n",
        "carrier for tensors.\n",
        "The benefit of using TensorDict over plain tensors is that it enables us to\n",
        "handle simple and complex data structures interchangeably. As our function\n",
        "signatures are very generic, it eliminates the challenge of accommodating\n",
        "different data formats. In simpler terms, after this brief tutorial,\n",
        "you will be capable of operating on both simple and highly complex\n",
        "environments, as their user-facing API is identical and simple!\n",
        "\n",
        "Let's put the environment into action and see what a tensordict instance\n",
        "looks like:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R3fJ1sQItId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c8d4fd-1fb3-4b63-add1-b377cea86d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "reset = env.reset()\n",
        "print(reset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDklZogZItId"
      },
      "source": [
        "Now let's take a random action in the action space. First, sample the action:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eUb24wMItIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dfefce-db3c-45f0-f1cc-f6f09ab89299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "reset_with_action = env.rand_action(reset)\n",
        "print(reset_with_action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BND_ouuyItIe"
      },
      "source": [
        "This tensordict has the same structure as the one obtained from\n",
        ":meth:`~torchrl.envs.EnvBase` with an additional ``\"action\"`` entry.\n",
        "You can access the action easily, like you would do with a regular\n",
        "dictionary:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRDbRGVBItIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9829165-2a7f-4117-a52a-6790b9bb760d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.9673])\n"
          ]
        }
      ],
      "source": [
        "print(reset_with_action[\"action\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6v965-5ItIe"
      },
      "source": [
        "We now need to pass this action to the environment.\n",
        "We'll be passing the entire tensordict to the ``step`` method, since there\n",
        "might be more than one tensor to be read in more advanced cases like\n",
        "Multi-Agent RL or stateless environments:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6FblvZhItIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8c7d77-3b70-4652-d4e1-121de3c5f70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "stepped_data = env.step(reset_with_action)\n",
        "print(stepped_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xbcdKb7ItIf"
      },
      "source": [
        "Again, this new tensordict is identical to the previous one except for the\n",
        "fact that it has a ``\"next\"`` entry (itself a tensordict!) containing the\n",
        "observation, reward and done state resulting from\n",
        "our action.\n",
        "\n",
        "We call this format TED, for\n",
        "`TorchRL Episode Data format <TED-format>`. It is\n",
        "the ubiquitous way of representing data in the library, both dynamically like\n",
        "here, or statically with offline datasets.\n",
        "\n",
        "The last bit of information you need to run a rollout in the environment is\n",
        "how to bring that ``\"next\"`` entry at the root to perform the next step.\n",
        "TorchRL provides a dedicated :func:`~torchrl.envs.utils.step_mdp` function\n",
        "that does just that: it filters out the information you won't need and\n",
        "delivers a data structure corresponding to your observation after a step in\n",
        "the Markov Decision Process, or MDP.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crd0igdDItIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e1045b-5225-4729-e40a-591795aab4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "from torchrl.envs import step_mdp\n",
        "\n",
        "data = step_mdp(stepped_data)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ2m6xGDItIg"
      },
      "source": [
        "## Environment rollouts\n",
        "\n",
        "\n",
        "Writing down those three steps (computing an action, making a step,\n",
        "moving in the MDP) can be a bit tedious and repetitive. Fortunately,\n",
        "TorchRL provides a nice :meth:`~torchrl.envs.EnvBase.rollout` function that\n",
        "allows you to run them in a closed loop at will:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nMahWLUItIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2034297-df9e-4771-de90-246d171a4d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "rollout = env.rollout(max_steps=10)\n",
        "print(rollout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR1QxMYUItIg"
      },
      "source": [
        "This data looks pretty much like the ``stepped_data`` above with the\n",
        "exception of its batch-size, which now equates the number of steps we\n",
        "provided through the ``max_steps`` argument. The magic of tensordict\n",
        "doesn't end there: if you're interested in a single transition of this\n",
        "environment, you can index the tensordict like you would index a tensor:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h6yBFAhItIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec3c5c9-1780-4074-a0ae-bbeca242f122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "transition = rollout[3]\n",
        "print(transition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1UqtHuQItIh"
      },
      "source": [
        ":class:`~tensordict.TensorDict` will automatically check if the index you\n",
        "provided is a key (in which case we index along the key-dimension) or a\n",
        "spatial index like here.\n",
        "\n",
        "Executed as such (without a policy), the ``rollout`` method may seem rather\n",
        "useless: it just runs random actions. If a policy is available, it can\n",
        "be passed to the method and used to collect data.\n",
        "\n",
        "Nevertheless, it can useful to run a naive, policyless rollout at first to\n",
        "check what is to be expected from an environment at a glance.\n",
        "\n",
        "To appreciate the versatility of TorchRL's API, consider the fact that the\n",
        "rollout method is universally applicable. It functions across **all** use\n",
        "cases, whether you're working with a single environment like this one,\n",
        "multiple copies across various processes, a multi-agent environment, or even\n",
        "a stateless version of it!\n",
        "\n",
        "\n",
        "## Transforming an environment\n",
        "\n",
        "Most of the time, you'll want to modify the output of the environment to\n",
        "better suit your requirements. For example, you might want to monitor the\n",
        "number of steps executed since the last reset, resize images, or stack\n",
        "consecutive observations together.\n",
        "\n",
        "In this section, we'll examine a simple transform, the\n",
        ":class:`~torchrl.envs.transforms.StepCounter` transform.\n",
        "The complete list of transforms can be found\n",
        "`here <transforms>`.\n",
        "\n",
        "The transform is integrated with the environment through a\n",
        ":class:`~torchrl.envs.transforms.TransformedEnv`:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb4lT2aUItIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a933c54-f8bc-489e-87fd-7e570bff69dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "from torchrl.envs import StepCounter, TransformedEnv\n",
        "\n",
        "transformed_env = TransformedEnv(env, StepCounter(max_steps=10))\n",
        "rollout = transformed_env.rollout(max_steps=100)\n",
        "print(rollout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp9JJ-PhItIi"
      },
      "source": [
        "As you can see, our environment now has one more entry, ``\"step_count\"`` that\n",
        "tracks the number of steps since the last reset.\n",
        "Given that we passed the optional\n",
        "argument ``max_steps=10`` to the transform constructor, we also truncated the\n",
        "trajectory after 10 steps (not completing a full rollout of 100 steps like\n",
        "we asked with the ``rollout`` call). We can see that the trajectory was\n",
        "truncated by looking at the truncated entry:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvTnkVoBItIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a14dd5a-736e-47f9-8b39-f48f8be10b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True]])\n"
          ]
        }
      ],
      "source": [
        "print(rollout[\"next\", \"truncated\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdgeRyFvItIi"
      },
      "source": [
        "This is all for this short introduction to TorchRL's environment API!\n",
        "\n",
        "## Next steps\n",
        "\n",
        "To explore further what TorchRL's environments can do, go and check:\n",
        "\n",
        "- The :meth:`~torchrl.envs.EnvBase.step_and_maybe_reset` method that packs\n",
        "  together :meth:`~torchrl.envs.EnvBase.step`,\n",
        "  :func:`~torchrl.envs.utils.step_mdp` and\n",
        "  :meth:`~torchrl.envs.EnvBase.reset`.\n",
        "- Some environments like :class:`~torchrl.envs.GymEnv` support rendering\n",
        "  through the ``from_pixels`` argument. Check the class docstrings to know\n",
        "  more!\n",
        "- The batched environments, in particular :class:`~torchrl.envs.ParallelEnv`\n",
        "  which allows you to run multiple copies of one same (or different!)\n",
        "  environments on multiple processes.\n",
        "- Design your own environment with the\n",
        "  `Pendulum tutorial <pendulum_tuto>` and learn about specs and\n",
        "  stateless environments.\n",
        "- See the more in-depth tutorial about environments\n",
        "  `in the dedicated tutorial <envs_tuto>`;\n",
        "- Check the\n",
        "  `multi-agent  environment API <MARL-environment-API>`\n",
        "  if you're interested in MARL;\n",
        "- TorchRL has many tools to interact with the Gym API such as\n",
        "  a way to register TorchRL envs in the Gym register through\n",
        "  :meth:`~torchrl.envs.EnvBase.register_gym`, an API to read\n",
        "  the info dictionaries through\n",
        "  :meth:`~torchrl.envs.EnvBase.set_info_dict_reader` or a way\n",
        "  to control the gym backend thanks to\n",
        "  :func:`~torchrl.envs.set_gym_backend`.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
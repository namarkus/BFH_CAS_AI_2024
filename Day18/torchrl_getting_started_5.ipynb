{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCbuZ2dKJsZp"
      },
      "source": [
        "\n",
        "# Get started with your own first training loop\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gymnasium==0.29.1 torch torchrl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD6Sx4sXsWGf",
        "outputId": "bd85244b-ad5b-4a44-ca7d-5282a58c5340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Collecting tensordict>=0.7.0 (from torchrl)\n",
            "  Downloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, tensordict, torchrl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.0\n",
            "    Uninstalling gymnasium-1.1.0:\n",
            "      Successfully uninstalled gymnasium-1.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 tensordict-0.7.2 torch-2.6.0 torchrl-0.7.1 triton-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rN9zy5RJsZt"
      },
      "source": [
        "Time to wrap up everything we've learned so far in this Getting Started\n",
        "series!\n",
        "\n",
        "In this tutorial, we will be writing the most basic training loop there is\n",
        "using only components we have presented in the previous lessons.\n",
        "\n",
        "We'll be using DQN with a CartPole environment as a prototypical example.\n",
        "\n",
        "We will be voluntarily keeping the verbosity to its minimum, only linking\n",
        "each section to the related tutorial.\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "We'll be using a gym environment with a :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform. If you need a refresher, check our these features are presented in\n",
        "`the environment tutorial <gs_env_ted>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU9kcbSkJsZu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import time\n",
        "\n",
        "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
        "\n",
        "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
        "env.set_seed(0)\n",
        "\n",
        "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B34NOeZ56not",
        "outputId": "9d43b6fa-df01-404e-d397-11a2ffeca2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHot(\n",
              "    shape=torch.Size([2]),\n",
              "    space=CategoricalBox(n=2),\n",
              "    device=cpu,\n",
              "    dtype=torch.int64,\n",
              "    domain=discrete)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUGtT6-VJsZv"
      },
      "source": [
        "## Designing a policy\n",
        "\n",
        "The next step is to build our policy.\n",
        "We'll be making a regular, deterministic\n",
        "version of the actor to be used within the\n",
        "`loss module <gs_optim>` and during\n",
        "`evaluation <gs_logging>`.\n",
        "Next, we will augment it with an exploration module\n",
        "for `inference <gs_storage>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Okcn3FVGJsZw"
      },
      "outputs": [],
      "source": [
        "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
        "\n",
        "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
        "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
        "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
        "exploration_module = EGreedyModule(\n",
        "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
        ")\n",
        "policy_explore = Seq(policy, exploration_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_spec"
      ],
      "metadata": {
        "id": "efwNdgNT85vL",
        "outputId": "c1f36cd7-6289-4d6f-b3b4-fe0b958b1c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHot(\n",
              "    shape=torch.Size([2]),\n",
              "    space=CategoricalBox(n=2),\n",
              "    device=cpu,\n",
              "    dtype=torch.int64,\n",
              "    domain=discrete)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kqbrETJsZw"
      },
      "source": [
        "## Data Collector and replay buffer\n",
        "\n",
        "Here comes the data part: we need a\n",
        "`data collector <gs_storage_collector>` to easily get batches of data\n",
        "and a `replay buffer <gs_storage_rb>` to store that data for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX6c1Lh3JsZw"
      },
      "outputs": [],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
        "\n",
        "init_rand_steps = 5000\n",
        "frames_per_batch = 100\n",
        "optim_steps = 10\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy_explore,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=-1,\n",
        "    init_random_frames=init_rand_steps,\n",
        ")\n",
        "rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n",
        "\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osYG-QBDJsZx"
      },
      "source": [
        "## Loss module and optimizer\n",
        "\n",
        "We build our loss as indicated in the `dedicated tutorial <gs_optim>`, with\n",
        "its optimizer and target parameter updater:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1StzFxkBJsZx"
      },
      "outputs": [],
      "source": [
        "from torchrl.objectives import DQNLoss, SoftUpdate\n",
        "\n",
        "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
        "optim = Adam(loss.parameters(), lr=0.02)\n",
        "updater = SoftUpdate(loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSUKSFfFJsZx"
      },
      "source": [
        "## Logger\n",
        "\n",
        "We'll be using a CSV logger to log our results, and save rendered videos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSSQWQAcJsZx"
      },
      "outputs": [],
      "source": [
        "from torchrl._utils import logger as torchrl_logger\n",
        "from torchrl.record import CSVLogger, VideoRecorder\n",
        "\n",
        "path = \"./training_loop\"\n",
        "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
        "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
        "record_env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpUT03nzJsZy"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Instead of fixing a specific number of iterations to run, we will keep on\n",
        "training the network until it reaches a certain performance (arbitrarily\n",
        "defined as 200 steps in the environment -- with CartPole, success is defined\n",
        "as having longer trajectories).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUxBiwLBJsZy"
      },
      "outputs": [],
      "source": [
        "total_count = 0\n",
        "total_episodes = 0\n",
        "t0 = time.time()\n",
        "for i, data in enumerate(collector):\n",
        "    # Write data in replay buffer\n",
        "    rb.extend(data)\n",
        "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
        "    if len(rb) > init_rand_steps:\n",
        "        # Optim loop (we do several optim steps\n",
        "        # per batch collected for efficiency)\n",
        "        for _ in range(optim_steps):\n",
        "            sample = rb.sample(128)\n",
        "            loss_vals = loss(sample)\n",
        "            loss_vals[\"loss\"].backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            # Update exploration factor\n",
        "            exploration_module.step(data.numel())\n",
        "            # Update target params\n",
        "            updater.step()\n",
        "            if i % 10:\n",
        "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
        "            total_count += data.numel()\n",
        "            total_episodes += data[\"next\", \"done\"].sum()\n",
        "    if max_length > 200:\n",
        "        break\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "torchrl_logger.info(\n",
        "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIn-5E1QJsZz"
      },
      "source": [
        "## Rendering\n",
        "\n",
        "Finally, we run the environment for as many steps as we can and save the\n",
        "video locally (notice that we are not exploring).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5N8ZTvuJsZz"
      },
      "outputs": [],
      "source": [
        "record_env.rollout(max_steps=1000, policy=policy)\n",
        "video_recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH2cvG8WJsZz"
      },
      "source": [
        "This is what your rendered CartPole video will look like after a full\n",
        "training loop:\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "\n",
        "This concludes our series of \"Getting started with TorchRL\" tutorials!\n",
        "Feel free to share feedback about it on GitHub.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}